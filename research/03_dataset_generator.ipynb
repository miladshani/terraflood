{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "import affine\n",
    "import os\n",
    "from shapely.geometry import box\n",
    "from rasterio.coords import BoundingBox\n",
    "from rasterio.mask import mask as masker\n",
    "import pystac\n",
    "\n",
    "# RAM check\n",
    "import psutil# Import libraries\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.411264\n"
     ]
    }
   ],
   "source": [
    "# RAM check\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input paths\n",
    "# load_vv = Path(\"../data/input_old_nigeria/vv/vv.tif\")\n",
    "# load_mask = Path(\"../data/input_old_nigeria/mask/merged/mask.tif\")\n",
    "# load_hand = Path(\"../data/input_old_nigeria/hand/hand.tif\")\n",
    "\n",
    "# input paths\n",
    "load_vv = Path(\"../data/input_scene_4/vv/corrected/vv.tif\")\n",
    "load_mask = Path(\"../data/input_scene_4/mask/corrected/mask.tif\")\n",
    "load_hand = Path(\"../data/input_scene_4/hand/hand.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "OUTPUT_SIZE = (256, 256)\n",
    "DROPNA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change CRS system\n",
    "# REPROJECTION CRS WITHOUT SAVING\n",
    "# KEEPS IN --> RAM <--\n",
    "\n",
    "\n",
    "def reproject_crs(file_path, target_crs):\n",
    "    \"\"\"Function to load tiff file from path\n",
    "    with desired crs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input GeoTIFF file\n",
    "    src = rio.open(file_path)\n",
    "    print(type(src))\n",
    "\n",
    "    # Read metadata\n",
    "    src_crs = src.crs\n",
    "    src_transform = src.transform\n",
    "    src_width = src.width\n",
    "    src_height = src.height\n",
    "\n",
    "    # Calculate the transform for reprojecting\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src_crs, target_crs, src_width, src_height, *src.bounds\n",
    "    )\n",
    "\n",
    "    # Create options for the output file\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update(\n",
    "        {\"crs\": target_crs, \"transform\": transform, \"width\": width, \"height\": height}\n",
    "    )\n",
    "\n",
    "    # Create an in-memory dataset\n",
    "    memfile = MemoryFile()\n",
    "    dst = memfile.open(**kwargs)\n",
    "\n",
    "    # Reproject and write to the in-memory dataset\n",
    "    reproject(\n",
    "        source=rio.band(src, 1),\n",
    "        destination=rio.band(dst, 1),\n",
    "        src_transform=src_transform,\n",
    "        src_crs=src_crs,\n",
    "        dst_transform=transform,\n",
    "        dst_crs=target_crs,\n",
    "        resampling=Resampling.nearest,\n",
    "    )\n",
    "    src.close()\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change CRS system\n",
    "# REPROJECTION CRS WITHOUT SAVING\n",
    "# KEEPS IN --> RAM <--\n",
    "\n",
    "\n",
    "def reproject_crs2(file_path, target_crs):\n",
    "    \"\"\"Function to load tiff file from path\n",
    "    with desired crs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input GeoTIFF file\n",
    "    with rio.open(file_path) as src:\n",
    "        print(type(src))\n",
    "\n",
    "        # Read metadata\n",
    "        src_crs = src.crs\n",
    "        src_transform = src.transform\n",
    "        src_width = src.width\n",
    "        src_height = src.height\n",
    "\n",
    "        # Calculate the transform for reprojecting\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src_crs, target_crs, src_width, src_height, *src.bounds\n",
    "        )\n",
    "\n",
    "        # Create options for the output file\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update(\n",
    "            {\n",
    "                \"crs\": target_crs,\n",
    "                \"transform\": transform,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Create an in-memory dataset\n",
    "        memfile = MemoryFile()\n",
    "        dst = memfile.open(**kwargs)\n",
    "\n",
    "        # Reproject and write to the in-memory dataset\n",
    "        reproject(\n",
    "            source=rio.band(src, 1),\n",
    "            destination=rio.band(dst, 1),\n",
    "            src_transform=src_transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest,\n",
    "        )\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rasterio.io.DatasetReader'>\n",
      "<class 'rasterio.io.DatasetReader'>\n",
      "<class 'rasterio.io.DatasetReader'>\n"
     ]
    }
   ],
   "source": [
    "# Loading all files with CRS:32632 as example\n",
    "target_crs = CRS.from_epsg(32632)\n",
    "vv = reproject_crs2(load_vv, target_crs)\n",
    "mask = reproject_crs2(load_mask, target_crs)\n",
    "hand = reproject_crs2(load_hand, target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load check\n",
    "# mask.read(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2906.329088\n"
     ]
    }
   ],
   "source": [
    "# Memory check\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': 0.0, 'width': 10013, 'height': 9231, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(42.74890388953347, 0.0, 9262106.148155086,\n",
      "       0.0, -42.74890388953347, 8051513.363165323)}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': 255.0, 'width': 18604, 'height': 17312, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(22.838760654556694, 0.0, 9264867.293830955,\n",
      "       0.0, -22.838760654556694, 8050302.032340328)}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -9999.0, 'width': 15585, 'height': 14783, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(198.79103795581588, 0.0, 8288255.774400535,\n",
      "       0.0, -198.79103795581588, 9236149.514951987)}\n"
     ]
    }
   ],
   "source": [
    "print(vv.meta, mask.meta, hand.meta, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundingBox(left=9262106.148155086, bottom=7656898.231361039, right=9690150.922800984, top=8051513.363165323)\n",
      "BoundingBox(left=9264867.293830955, bottom=7654917.4078886425, right=9689759.597048327, top=8050302.032340328)\n",
      "BoundingBox(left=8288255.774400535, bottom=6297421.600851161, right=11386414.100941926, top=9236149.514951987)\n"
     ]
    }
   ],
   "source": [
    "print(vv.bounds, mask.bounds, hand.bounds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting overlap bounding box between files\n",
    "# So to keep parts of data that are needed in the RAM\n",
    "\n",
    "left = [vv.bounds.left, mask.bounds.left, hand.bounds.left]\n",
    "bottom = [vv.bounds.bottom, mask.bounds.bottom, hand.bounds.bottom]\n",
    "right = [vv.bounds.right, mask.bounds.right, hand.bounds.right]\n",
    "top = [vv.bounds.top, mask.bounds.top, hand.bounds.top]\n",
    "\n",
    "overlap_bounds = BoundingBox(\n",
    "    left=max(left), bottom=max(bottom), right=min(right), top=min(top)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((9689759.597048327 7656898.231361039, 9689759.597048327 8050302.032340328, 9264867.293830955 8050302.032340328, 9264867.293830955 7656898.231361039, 9689759.597048327 7656898.231361039))\n"
     ]
    }
   ],
   "source": [
    "# Convert bounds to polygon\n",
    "overlap_polygon = box(*overlap_bounds)\n",
    "print(overlap_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img, crop_transform = masker(hand, shapes=[overlap_polygon], crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1980, 2139)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cropped image shape\n",
    "crop_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MemoryFile() out of crop_img\n",
    "profile = hand.profile.copy()\n",
    "profile.update(\n",
    "    driver=\"GTiff\",\n",
    "    height=crop_img.shape[1],\n",
    "    width=crop_img.shape[2],\n",
    "    transform=crop_transform,\n",
    ")\n",
    "\n",
    "memfile = MemoryFile()\n",
    "cropped_hand = memfile.open(**profile)\n",
    "cropped_hand.write(crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff',\n",
       " 'dtype': 'float32',\n",
       " 'nodata': -9999.0,\n",
       " 'width': 2139,\n",
       " 'height': 1980,\n",
       " 'count': 1,\n",
       " 'crs': CRS.from_epsg(32632),\n",
       " 'transform': Affine(198.79103795581588, 0.0, 9264717.352839503,\n",
       "        0.0, -198.79103795581588, 8050360.973545546)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped_hand.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(198.79103795581588, 0.0, 9264717.352839503,\n",
       "       0.0, -198.79103795581588, 8050360.973545546)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1980, 2139)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(198.79103795581588, 0.0, 8288255.774400535,\n",
       "       0.0, -198.79103795581588, 9236149.514951987)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14783, 15585)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.39931219629677"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger = hand.shape[0] * hand.shape[1]\n",
    "smaller = crop_img.shape[1] * crop_img.shape[2]\n",
    "\n",
    "bigger / smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change the resolution of files to desired one\n",
    "\n",
    "\n",
    "def rescale_image(input_file, scale_factor):\n",
    "    # Read the data from the source file\n",
    "    src = input_file\n",
    "    data = src.read(\n",
    "        out_shape=(\n",
    "            src.count,\n",
    "            int(src.height * scale_factor),\n",
    "            int(src.width * scale_factor),\n",
    "        ),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    # Update the metadata\n",
    "    transform = src.transform * src.transform.scale(\n",
    "        (src.width / data.shape[-1]), (src.height / data.shape[-2])\n",
    "    )\n",
    "\n",
    "    # Update the profile\n",
    "    profile = src.profile\n",
    "    profile.update(\n",
    "        driver=\"GTiff\",\n",
    "        height=data.shape[1],\n",
    "        width=data.shape[2],\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    memfile = MemoryFile()\n",
    "    scaled_dataset = memfile.open(**profile)\n",
    "    scaled_dataset.write(data)\n",
    "\n",
    "    return scaled_dataset, profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.5342537135823142 4.650201990430153\n"
     ]
    }
   ],
   "source": [
    "# Set resolution to standard\n",
    "# RES = 20\n",
    "RES = vv.res[0]\n",
    "vv_refactor = vv.res[0] / RES\n",
    "mask_refactor = mask.res[0] / RES\n",
    "hand_refactor = cropped_hand.res[0] / RES\n",
    "print(vv_refactor, mask_refactor, hand_refactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_scaled, _ = rescale_image(vv, vv_refactor)\n",
    "mask_scaled, _ = rescale_image(mask, mask_refactor)\n",
    "hand_scaled, _ = rescale_image(cropped_hand, hand_refactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.74890388953347, 42.74890388953347)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': 0.0, 'width': 10013, 'height': 9231, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(42.74890388953347, 0.0, 9262106.148155086,\n",
      "       0.0, -42.74890388953347, 8051513.363165323)}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': 255.0, 'width': 9939, 'height': 9249, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(42.75000535439911, 0.0, 9264867.293830955,\n",
      "       0.0, -42.74890522777441, 8050302.032340328)}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -9999.0, 'width': 9946, 'height': 9207, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(42.75226525110498, 0.0, 9264717.352839503,\n",
      "       0.0, -42.75076085071309, 8050360.973545546)}\n"
     ]
    }
   ],
   "source": [
    "print(vv_scaled.meta, mask_scaled.meta, hand_scaled.meta, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3993.51808\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "\n",
    "    # OK\n",
    "    def __init__(self, collection_id):\n",
    "        \"\"\"Initiates an empty list. To be fed with different images data\"\"\"\n",
    "        self.images = []\n",
    "        self.ref_flag = False\n",
    "        self.clipped_addresses = []\n",
    "        self.row = 0\n",
    "        self.col = 0\n",
    "        self.collection_id = collection_id\n",
    "\n",
    "    # OK\n",
    "    # THE WAT THAT NO DATA ADDED?\n",
    "    def add(self, image, name: str, set_nodata: int = 0):\n",
    "        \"\"\"Creates a dictionary of infromation about the given image.\n",
    "        Then adds that dict to the images_data list.\n",
    "        \"\"\"\n",
    "\n",
    "        # Correcting Nodata\n",
    "        if image.nodata == None:\n",
    "            image.nodata = set_nodata\n",
    "\n",
    "        image_dict = dict()\n",
    "        image_dict[\"name\"] = name\n",
    "        image_dict[\"image\"] = image\n",
    "        image_dict[\"band\"] = image.read(1)\n",
    "\n",
    "        self.images.append(image_dict)\n",
    "\n",
    "    # OK\n",
    "    def set_ref_image(self, name: str = \"vv\"):\n",
    "        \"\"\"Sets the image file which all dataset should be cliped\n",
    "        with respect to that.\n",
    "        Input:str -> name of the image\n",
    "        Output:Bool -> True if done, False name not in the list\n",
    "        \"\"\"\n",
    "        # Checks if the name is in added images list\n",
    "        check_availibility = [True for image in self.images if image[\"name\"] == name]\n",
    "        if not check_availibility:\n",
    "            return False\n",
    "\n",
    "        for image in self.images:\n",
    "            if image[\"name\"] == name:\n",
    "                self.ref_name = name\n",
    "                self.ref_image = image[\"image\"]\n",
    "                self.ref_crs = image[\"image\"].crs\n",
    "                self.ref_res = image[\"image\"].res\n",
    "                self.ref_shape = image[\"image\"].shape\n",
    "\n",
    "        self.refrence_flag = True\n",
    "        return True\n",
    "\n",
    "    # OUTPUT IS NOT IMAGE, IS A LIST\n",
    "    # NEED CHANGE?\n",
    "    # Self.band needs to change\n",
    "    def _create_clipped_image(self, image, band, row, col, height, width, name):\n",
    "\n",
    "        ### need change self.band\n",
    "        # band data array\n",
    "\n",
    "        clipped_band = band[\n",
    "            row : row + height,\n",
    "            col : col + width,\n",
    "        ]\n",
    "        clipped_band = np.array(clipped_band)\n",
    "\n",
    "        # Positioning\n",
    "        tcol, trow = image.transform * (col, row)\n",
    "        new_transform = affine.Affine(\n",
    "            image.transform[0],\n",
    "            image.transform[1],\n",
    "            tcol,\n",
    "            image.transform[3],\n",
    "            image.transform[4],\n",
    "            trow,\n",
    "        )\n",
    "\n",
    "        # creating clipped_image\n",
    "        return_image = [\n",
    "            clipped_band,\n",
    "            image.crs,\n",
    "            new_transform,\n",
    "            clipped_band.shape[0],\n",
    "            clipped_band.shape[1],\n",
    "            image.dtypes[0],\n",
    "            image.nodata,\n",
    "            name,\n",
    "        ]\n",
    "        return return_image\n",
    "\n",
    "    def _check_complete(self, images, height, width):\n",
    "        \"\"\"\n",
    "        If any image in the same coordination has\n",
    "        nodata value returns False, otherwise True.\n",
    "        \"\"\"\n",
    "        # for image in images:\n",
    "        #     with image.read(1) as band:\n",
    "        #         if sum(sum(band == image.nodata)):\n",
    "        #             return False\n",
    "        # return True\n",
    "        print(\"images sent to complete_check method:\")\n",
    "        for img in images:\n",
    "            print(img[7])\n",
    "\n",
    "        for image in images:\n",
    "\n",
    "            print(image[7], \":\")\n",
    "            print(\"type(image[0])\", type(image[0]))\n",
    "            print(\"type(image[6])\", type(image[6]))\n",
    "            print(\"type sum\", type(sum(image[0] == image[6])))\n",
    "\n",
    "            if image[0].shape != (height, width):\n",
    "                print(\"shape was not complete -> shape:\", image[0].shape)\n",
    "                return False\n",
    "\n",
    "            # if type(sum(image[0]==image[6])) == int:\n",
    "            #     return False\n",
    "            if sum(sum(image[0] == image[6])):\n",
    "                print(\"none found\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _save_image(self, save_path_format, image, col, row, mask_coverage):\n",
    "        \"\"\"\n",
    "        Saves Clipped image into file\n",
    "        \"\"\"\n",
    "        name = image[7]\n",
    "\n",
    "        file_name = save_path_format.format(\n",
    "            name=name, col=col, row=row, mask_coverage=mask_coverage\n",
    "        )\n",
    "        file_name = Path(file_name)\n",
    "\n",
    "        os.makedirs(os.path.split(file_name)[0], exist_ok=True)\n",
    "\n",
    "        print(\"SAVE CALLED\", file_name)\n",
    "\n",
    "        with rio.open(\n",
    "            file_name,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=image[3],\n",
    "            width=image[4],\n",
    "            count=1,\n",
    "            dtype=image[5],\n",
    "            crs=image[1],\n",
    "            transform=image[2],\n",
    "        ) as dst:\n",
    "            dst.write(image[0], 1)\n",
    "        self.clipped_addresses.append(file_name)\n",
    "        return file_name\n",
    "\n",
    "    def _xy_from_row_col(self, image, row, col):\n",
    "        \"\"\"Returns coordinate of a pixel in one image from it's (row,col)\"\"\"\n",
    "        x, y = image.xy(row, col)\n",
    "        return x, y\n",
    "\n",
    "    def _row_col_from_xy(self, image, x, y):\n",
    "        \"\"\"Returns (row,col) position of a pixel from it's coordinate\"\"\"\n",
    "        row, col = image.index(x, y)\n",
    "        return row, col\n",
    "\n",
    "    def run(self, height: int = 256, width: int = 256, only_complete: bool = True):\n",
    "\n",
    "        save_path_format = \"../data/dataset/scene4/x{row}_y{col}_{mask_coverage}/{name}.tif\"\n",
    "\n",
    "        row = self.row\n",
    "        while row < self.ref_shape[0]:\n",
    "            col = self.col\n",
    "            while col < self.ref_shape[1]:\n",
    "\n",
    "                mask_coverage = 0\n",
    "                clipped_images = []\n",
    "                for img in self.images:\n",
    "\n",
    "                    name = img[\"name\"]\n",
    "                    image = img[\"image\"]\n",
    "                    band = img[\"band\"]\n",
    "\n",
    "                    # Coverting row,col of refrence image to row,col of the current image\n",
    "                    x, y = self._xy_from_row_col(self.ref_image, row=row, col=col)\n",
    "                    trow, tcol = self._row_col_from_xy(image=image, x=x, y=y)\n",
    "\n",
    "                    # Creating cropped image\n",
    "                    clipped_image = self._create_clipped_image(\n",
    "                        image, band, trow, tcol, height, width, name\n",
    "                    )\n",
    "\n",
    "                    # Append to list of images on same location\n",
    "                    clipped_images.append(clipped_image)\n",
    "\n",
    "                    # Calculate mask_coverage for the area of interest\n",
    "                    if name == \"mask\":\n",
    "                        mask_coverage = self._get_mask_coverage(clipped_image)\n",
    "                        print(\"MASK COVERAGE:\", mask_coverage)\n",
    "\n",
    "                ### _check_complete\n",
    "                print(\"ROW:\", row, \"COL:\", col)\n",
    "\n",
    "                if mask_coverage == -1:\n",
    "                    complete_check = False\n",
    "                else:\n",
    "                    complete_check = self._check_complete(clipped_images, height, width)\n",
    "\n",
    "                print(\"complete check:\", complete_check)\n",
    "                ### save images\n",
    "                if complete_check:\n",
    "                    # Calculate water coverage in the image\n",
    "                    # Save images into path\n",
    "                    for image in clipped_images:\n",
    "                        self._save_image(\n",
    "                            save_path_format, image, col, row, mask_coverage\n",
    "                        )\n",
    "                ### add to STAC\n",
    "                ### append saved images into a list?\n",
    "                # ->## Done inside _save_image method\n",
    "\n",
    "                # Update column position\n",
    "                col = col + width\n",
    "\n",
    "            # Update row position\n",
    "            row = row + height\n",
    "\n",
    "        print(\"Tiles saved successfully\")\n",
    "        return self.clipped_addresses\n",
    "\n",
    "    def set_row_col_for_generator(self, row, col):\n",
    "        \"\"\"This method is used when a half bulit collection is loaded.\n",
    "        To continue generating clips from the given row, col\n",
    "        \"\"\"\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "\n",
    "    def _create_collection(self):\n",
    "\n",
    "        self.collection = pystac.Collection(\n",
    "            id=\"\",\n",
    "            description=\"\",\n",
    "            extent=\"\",\n",
    "            title=\"\",\n",
    "            href=\"\",\n",
    "            extra_fields={},\n",
    "            catalog_type=\"\",\n",
    "            license=\"\",\n",
    "        )\n",
    "\n",
    "    # -------------- later ------------\n",
    "    def _get_mask_coverage(self, mask):\n",
    "        \"\"\"Returns the mask coverage in the scene\n",
    "        0 is considered as non covered area in input file\n",
    "        1 is considered as covered area in input file\n",
    "        Returns integer in range (0, 100)\n",
    "        \"\"\"\n",
    "\n",
    "        data = mask[0]\n",
    "        image_count = data.size\n",
    "        mask_count = (data == 1).sum()\n",
    "\n",
    "        # print(mask)\n",
    "        # print(data)\n",
    "\n",
    "        if image_count == 0:\n",
    "            return -1\n",
    "\n",
    "        return int((mask_count / image_count) * 100)\n",
    "\n",
    "    def _create_asset(self, file_href):\n",
    "        return pystac.Asset(\n",
    "            href=file_href,\n",
    "            media_type=pystac.MediaType.GEOTIFF,\n",
    "        )\n",
    "\n",
    "    def _create_item(\n",
    "        self,\n",
    "        id,\n",
    "        geometry,\n",
    "        bbox,\n",
    "    ):\n",
    "\n",
    "        item = pystac.Item()\n",
    "        item.id = id\n",
    "        item.geometry = geometry\n",
    "        item.bbox = bbox\n",
    "\n",
    "    pystac.Item(\n",
    "        id=\"\",  # ?\n",
    "        geometry=\"\",  #\n",
    "        bbox=\"\",  #\n",
    "        datetime=\"\",  #\n",
    "        start_datetime=\"\",  #\n",
    "        end_datetime=\"\",  #\n",
    "        href=\"\",  #\n",
    "        collection=\"\",  #\n",
    "        # for 1 or 2:\n",
    "        # \"water_coverage\": in percent%\n",
    "        # \"minimum MASK\" value\n",
    "        properties={},  # 1 -> 1 or 2\n",
    "        extra_fields={},  # 2 -> 1 or 2\n",
    "        assets={},  #\n",
    "    )\n",
    "\n",
    "    def _add_to_stac(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_generator = DatasetGenerator(collection_id=\"randomId\")\n",
    "ds_generator.add(vv_scaled, name=\"vv\", set_nodata=0.0)\n",
    "ds_generator.add(mask_scaled, name=\"mask\")\n",
    "ds_generator.add(hand_scaled, name=\"HAND\")\n",
    "\n",
    "ds_generator.set_ref_image(\"HAND\")\n",
    "paths = ds_generator.run(height=256, width=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5358.592\n"
     ]
    }
   ],
   "source": [
    "# Memory usage\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\t\t     input_scene_1  input_scene_4\n",
      "dataset_old_nigeria  input_scene_2  trials_output\n",
      "input_old_nigeria    input_scene_3  trials_output.zip\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
