{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - dataset blancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copy2, rmtree\n",
    "from scipy.ndimage import zoom\n",
    "from typing import Dict, List, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions \n",
    "\n",
    "def get_water_percentage(dir_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract the water percentage from the directory name.\n",
    "\n",
    "    Args:\n",
    "        dir_name (str): The name of the directory containing water percentage information.\n",
    "\n",
    "    Returns:\n",
    "        int: The water percentage extracted from the directory name.\n",
    "    \"\"\"\n",
    "    return int(dir_name.split('_')[2])\n",
    "\n",
    "def load_dataset(base_dir: str) -> Dict[str, List[Tuple[str, int]]]:\n",
    "    \"\"\"\n",
    "    Load dataset from the base directory.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Tuple[str, int]]]: A dictionary where keys are scene names and values are lists of tuples\n",
    "                                          with directory names and corresponding water percentages.\n",
    "    \"\"\"\n",
    "    dataset = {}\n",
    "    for scene in os.listdir(base_dir):\n",
    "        scene_path = os.path.join(base_dir, scene)\n",
    "        if os.path.isdir(scene_path):\n",
    "            dataset[scene] = []\n",
    "            for dir_name in os.listdir(scene_path):\n",
    "                water_percentage = get_water_percentage(dir_name)\n",
    "                dataset[scene].append((dir_name, water_percentage))\n",
    "    return dataset\n",
    "\n",
    "def bin_dataset(dataset: Dict[str, List[Tuple[str, int]]], bin_size: int) -> Dict[str, Dict[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Bin the dataset based on water percentage.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dict[str, List[Tuple[str, int]]]): The dataset to bin.\n",
    "        bin_size (int): The size of each bin for water percentage.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[int, List[str]]]: A dictionary where keys are scene names, and values are dictionaries\n",
    "                                          with bin indices as keys and lists of directory names as values.\n",
    "    \"\"\"\n",
    "    binned_dataset = {}\n",
    "    for scene, dirs in dataset.items():\n",
    "        binned_dataset[scene] = {}\n",
    "        for dir_name, water_percentage in dirs:\n",
    "            bin_index = water_percentage // bin_size\n",
    "            if bin_index not in binned_dataset[scene]:\n",
    "                binned_dataset[scene][bin_index] = []\n",
    "            binned_dataset[scene][bin_index].append(dir_name)\n",
    "    return binned_dataset\n",
    "\n",
    "def balance_dataset(binned_dataset: Dict[str, Dict[int, List[str]]]) -> Dict[str, Dict[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Balance the dataset by limiting the number of samples in each bin to the mean plus half the standard deviation.\n",
    "\n",
    "    Args:\n",
    "        binned_dataset (Dict[str, Dict[int, List[str]]]): The binned dataset to balance.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[int, List[str]]]: A balanced dataset with the number of samples in each bin adjusted.\n",
    "    \"\"\"\n",
    "    balanced_dataset = {}\n",
    "    for scene, bins in binned_dataset.items():\n",
    "        num_members = [len(bins[bin_index]) for bin_index in bins]\n",
    "        mean = np.mean(num_members)\n",
    "        std = np.std(num_members)\n",
    "        threshold = mean + (std / 2)\n",
    "        \n",
    "        balanced_dataset[scene] = {}\n",
    "        for bin_index, dirs in bins.items():\n",
    "            if len(dirs) > threshold:\n",
    "                dirs = random.sample(dirs, int(threshold))\n",
    "            balanced_dataset[scene][bin_index] = dirs\n",
    "    return balanced_dataset\n",
    "\n",
    "def apply_augmentations(data: np.ndarray, augmentation: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply the specified augmentation to the given data.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The data to augment.\n",
    "        augmentation (str): The type of augmentation to apply ('hf', 'vf', 'sc', 'tr', 'ro').\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The augmented data.\n",
    "    \"\"\"\n",
    "    if augmentation == 'hf':\n",
    "        return np.fliplr(data)\n",
    "    elif augmentation == 'vf':\n",
    "        return np.flipud(data)\n",
    "    elif augmentation == 'sc':\n",
    "        scale_factor = 1.2\n",
    "        zoom_factor = (scale_factor, scale_factor)\n",
    "        scaled_data = zoom(data, zoom_factor, order=1)  # Bilinear interpolation\n",
    "        start_x = (scaled_data.shape[0] - 256) // 2\n",
    "        start_y = (scaled_data.shape[1] - 256) // 2\n",
    "        return scaled_data[start_x:start_x + 256, start_y:start_y + 256]\n",
    "    elif augmentation == 'tr':\n",
    "        shift = 10\n",
    "        return np.roll(data, shift, axis=(0, 1))\n",
    "    elif augmentation == 'ro':\n",
    "        return np.rot90(data, 2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown augmentation type: {augmentation}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
