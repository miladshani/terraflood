{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - dataset blancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copy2, rmtree\n",
    "from scipy.ndimage import zoom\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style for enhanced aesthetics\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ inputs ------\n",
    "# Set directories\n",
    "input_dir = '../data/dataset/'\n",
    "output_dir = '../data/dataset_balanced/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions for >> BALANCED DATASET GENERATION <<\n",
    "\n",
    "def get_water_percentage(dir_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract the water percentage from the directory name.\n",
    "\n",
    "    Args:\n",
    "        dir_name (str): The name of the directory containing water percentage information.\n",
    "\n",
    "    Returns:\n",
    "        int: The water percentage extracted from the directory name.\n",
    "    \"\"\"\n",
    "    return int(dir_name.split('_')[2])\n",
    "\n",
    "def load_dataset(base_dir: str) -> Dict[str, List[Tuple[str, int]]]:\n",
    "    \"\"\"\n",
    "    Load dataset from the base directory.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Tuple[str, int]]]: A dictionary where keys are scene names and values are lists of tuples\n",
    "                                          with directory names and corresponding water percentages.\n",
    "    \"\"\"\n",
    "    dataset = {}\n",
    "    for scene in os.listdir(base_dir):\n",
    "        scene_path = os.path.join(base_dir, scene)\n",
    "        if os.path.isdir(scene_path):\n",
    "            dataset[scene] = []\n",
    "            for dir_name in os.listdir(scene_path):\n",
    "                water_percentage = get_water_percentage(dir_name)\n",
    "                dataset[scene].append((dir_name, water_percentage))\n",
    "    return dataset\n",
    "\n",
    "def bin_dataset(dataset: Dict[str, List[Tuple[str, int]]], bin_size: int) -> Dict[str, Dict[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Bin the dataset based on water percentage.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dict[str, List[Tuple[str, int]]]): The dataset to bin.\n",
    "        bin_size (int): The size of each bin for water percentage.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[int, List[str]]]: A dictionary where keys are scene names, and values are dictionaries\n",
    "                                          with bin indices as keys and lists of directory names as values.\n",
    "    \"\"\"\n",
    "    binned_dataset = {}\n",
    "    for scene, dirs in dataset.items():\n",
    "        binned_dataset[scene] = {}\n",
    "        for dir_name, water_percentage in dirs:\n",
    "            bin_index = water_percentage // bin_size\n",
    "            if bin_index not in binned_dataset[scene]:\n",
    "                binned_dataset[scene][bin_index] = []\n",
    "            binned_dataset[scene][bin_index].append(dir_name)\n",
    "    return binned_dataset\n",
    "\n",
    "def balance_dataset(binned_dataset: Dict[str, Dict[int, List[str]]]) -> Dict[str, Dict[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Balance the dataset by limiting the number of samples in each bin to the mean plus half the standard deviation.\n",
    "\n",
    "    Args:\n",
    "        binned_dataset (Dict[str, Dict[int, List[str]]]): The binned dataset to balance.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[int, List[str]]]: A balanced dataset with the number of samples in each bin adjusted.\n",
    "    \"\"\"\n",
    "    balanced_dataset = {}\n",
    "    for scene, bins in binned_dataset.items():\n",
    "        num_members = [len(bins[bin_index]) for bin_index in bins]\n",
    "        mean = np.mean(num_members)\n",
    "        std = np.std(num_members)\n",
    "        threshold = mean + (std / 2)\n",
    "        \n",
    "        balanced_dataset[scene] = {}\n",
    "        for bin_index, dirs in bins.items():\n",
    "            if len(dirs) > threshold:\n",
    "                dirs = random.sample(dirs, int(threshold))\n",
    "            balanced_dataset[scene][bin_index] = dirs\n",
    "    return balanced_dataset\n",
    "\n",
    "def apply_augmentations(data: np.ndarray, augmentation: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply the specified augmentation to the given data.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The data to augment.\n",
    "        augmentation (str): The type of augmentation to apply ('hf', 'vf', 'sc', 'tr', 'ro').\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The augmented data.\n",
    "    \"\"\"\n",
    "    if augmentation == 'hf':\n",
    "        return np.fliplr(data)\n",
    "    elif augmentation == 'vf':\n",
    "        return np.flipud(data)\n",
    "    elif augmentation == 'sc':\n",
    "        scale_factor = 1.2\n",
    "        zoom_factor = (scale_factor, scale_factor)\n",
    "        scaled_data = zoom(data, zoom_factor, order=1)  # Bilinear interpolation\n",
    "        start_x = (scaled_data.shape[0] - 256) // 2\n",
    "        start_y = (scaled_data.shape[1] - 256) // 2\n",
    "        return scaled_data[start_x:start_x + 256, start_y:start_y + 256]\n",
    "    elif augmentation == 'tr':\n",
    "        shift = 10\n",
    "        return np.roll(data, shift, axis=(0, 1))\n",
    "    elif augmentation == 'ro':\n",
    "        return np.rot90(data, 2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown augmentation type: {augmentation}\")\n",
    "\n",
    "def augment_data(scene: str, dir_name: str, input_dir: str, output_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Augment data for a given scene and directory.\n",
    "\n",
    "    Args:\n",
    "        scene (str): The name of the scene.\n",
    "        dir_name (str): The name of the directory containing the data.\n",
    "        input_dir (str): The input directory containing the original data.\n",
    "        output_dir (str): The output directory to save augmented data.\n",
    "    \"\"\"\n",
    "    augmentations = ['hf', 'vf', 'sc', 'tr', 'ro']\n",
    "    \n",
    "    src_vv = os.path.join(input_dir, scene, dir_name, \"vv.tif\")\n",
    "    src_hand = os.path.join(input_dir, scene, dir_name, \"HAND.tif\")\n",
    "    src_mask = os.path.join(input_dir, scene, dir_name, \"mask.tif\")\n",
    "    \n",
    "    with rasterio.open(src_vv) as src:\n",
    "        vv_data = src.read(1)\n",
    "        vv_transform = src.transform\n",
    "    with rasterio.open(src_hand) as src:\n",
    "        hand_data = src.read(1)\n",
    "        hand_transform = src.transform\n",
    "    with rasterio.open(src_mask) as src:\n",
    "        mask_data = src.read(1)\n",
    "        mask_transform = src.transform\n",
    "\n",
    "    for aug in augmentations:\n",
    "        augmented_dir_name = f\"{dir_name}_{aug}\"\n",
    "        aug_vv = os.path.join(output_dir, scene, augmented_dir_name, \"vv.tif\")\n",
    "        aug_hand = os.path.join(output_dir, scene, augmented_dir_name, \"HAND.tif\")\n",
    "        aug_mask = os.path.join(output_dir, scene, augmented_dir_name, \"mask.tif\")\n",
    "        \n",
    "        os.makedirs(os.path.join(output_dir, scene, augmented_dir_name), exist_ok=True)\n",
    "        \n",
    "        vv_data_aug = apply_augmentations(vv_data, aug)\n",
    "        hand_data_aug = apply_augmentations(hand_data, aug)\n",
    "        mask_data_aug = apply_augmentations(mask_data, aug)\n",
    "\n",
    "        with rasterio.open(aug_vv, 'w', driver='GTiff', height=vv_data_aug.shape[0], width=vv_data_aug.shape[1], count=1, dtype=vv_data_aug.dtype, crs=src.crs, transform=vv_transform) as dst:\n",
    "            dst.write(vv_data_aug, 1)\n",
    "        with rasterio.open(aug_hand, 'w', driver='GTiff', height=hand_data_aug.shape[0], width=hand_data_aug.shape[1], count=1, dtype=hand_data_aug.dtype, crs=src.crs, transform=hand_transform) as dst:\n",
    "            dst.write(hand_data_aug, 1)\n",
    "        with rasterio.open(aug_mask, 'w', driver='GTiff', height=mask_data_aug.shape[0], width=mask_data_aug.shape[1], count=1, dtype=mask_data_aug.dtype, crs=src.crs, transform=mask_transform) as dst:\n",
    "            dst.write(mask_data_aug, 1)\n",
    "\n",
    "def create_balanced_dataset(balanced_dataset: Dict[str, Dict[int, List[str]]], input_dir: str, output_dir: str, augment: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Create a balanced dataset directory from the given balanced dataset.\n",
    "\n",
    "    Args:\n",
    "        balanced_dataset (Dict[str, Dict[int, List[str]]]): The balanced dataset to process.\n",
    "        input_dir (str): The input directory containing the original data.\n",
    "        output_dir (str): The output directory to save the balanced dataset.\n",
    "        augment (bool): Whether to apply augmentations to balance the dataset. Default is True.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_dir):\n",
    "        rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    all_bin_sizes = []\n",
    "    for scene, bins in balanced_dataset.items():\n",
    "        for bin_index, dirs in bins.items():\n",
    "            all_bin_sizes.append(len(dirs))\n",
    "    mean_bin_size = np.mean(all_bin_sizes)\n",
    "\n",
    "    for scene, bins in balanced_dataset.items():\n",
    "        for bin_index, dirs in bins.items():\n",
    "            for dir_name in dirs:\n",
    "                original_dir_name = f\"{dir_name}_na\"\n",
    "                original_dst_dir = os.path.join(output_dir, scene, original_dir_name)\n",
    "                os.makedirs(original_dst_dir, exist_ok=True)\n",
    "                \n",
    "                src_dir = os.path.join(input_dir, scene, dir_name)\n",
    "                copy2(os.path.join(src_dir, \"vv.tif\"), os.path.join(original_dst_dir, \"vv.tif\"))\n",
    "                copy2(os.path.join(src_dir, \"HAND.tif\"), os.path.join(original_dst_dir, \"HAND.tif\"))\n",
    "                copy2(os.path.join(src_dir, \"mask.tif\"), os.path.join(original_dst_dir, \"mask.tif\"))\n",
    "\n",
    "                if augment and len(dirs) < mean_bin_size:\n",
    "                    augment_data(scene, dir_name, input_dir, output_dir)\n",
    "\n",
    "def plot_sample_images(dataset: Dict[str, List[Tuple[str, int]]], input_dir: str, num_samples: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Plot sample images from the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dict[str, List[Tuple[str, int]]]): The dataset to sample images from.\n",
    "        input_dir (str): The directory containing the dataset.\n",
    "        num_samples (int): The number of samples to plot. Default is 5.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
    "    scenes = list(dataset.keys())\n",
    "    for i in range(num_samples):\n",
    "        scene = random.choice(scenes)\n",
    "        dir_name, _ = random.choice(dataset[scene])\n",
    "        vv_path = os.path.join(input_dir, scene, dir_name, \"vv.tif\")\n",
    "        hand_path = os.path.join(input_dir, scene, dir_name, \"HAND.tif\")\n",
    "        mask_path = os.path.join(input_dir, scene, dir_name, \"mask.tif\")\n",
    "        \n",
    "        with rasterio.open(vv_path) as src:\n",
    "            vv_data = src.read(1)\n",
    "        with rasterio.open(hand_path) as src:\n",
    "            hand_data = src.read(1)\n",
    "        with rasterio.open(mask_path) as src:\n",
    "            mask_data = src.read(1)\n",
    "\n",
    "        axs[i, 0].imshow(vv_data, cmap='gray')\n",
    "        axs[i, 0].set_title(f\"VV Band - {scene}/{dir_name}\")\n",
    "        axs[i, 1].imshow(hand_data, cmap='gray')\n",
    "        axs[i, 1].set_title(f\"HAND - {scene}/{dir_name}\")\n",
    "        axs[i, 2].imshow(mask_data, cmap='gray')\n",
    "        axs[i, 2].set_title(f\"Mask - {scene}/{dir_name}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def process_dataset(input_dir: str, output_dir: str, bin_size: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Main function to process the dataset: load, bin, balance, and augment data, and plot sample images.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): The directory containing the original dataset.\n",
    "        output_dir (str): The directory to save the balanced dataset.\n",
    "        bin_size (int): The size of each bin for water percentage. Default is 10.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(input_dir)\n",
    "    \n",
    "    # Plot sample images from the original dataset\n",
    "    plot_sample_images(dataset, input_dir)\n",
    "\n",
    "    binned_dataset = bin_dataset(dataset, bin_size)\n",
    "    balanced_dataset = balance_dataset(binned_dataset)\n",
    "    create_balanced_dataset(balanced_dataset, input_dir, output_dir)\n",
    "\n",
    "    # Plot sample images from the balanced dataset\n",
    "    balanced_dataset_loaded = load_dataset(output_dir)\n",
    "    plot_sample_images(balanced_dataset_loaded, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions for >> PLOTTING AND COMPARISON << between base dataset and balanced dataset\n",
    "\n",
    "def calculate_bin_distribution(dataset: Dict[str, List[Tuple[str, int]]], bin_size: int) -> Dict[str, Dict[int, int]]:\n",
    "    \"\"\"\n",
    "    Calculate the distribution of water percentages into bins.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dict[str, List[Tuple[str, int]]]): The dataset to be binned.\n",
    "        bin_size (int): The size of each bin.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[int, int]]: A dictionary where keys are scene names and values are dictionaries with bin indices as keys and counts as values.\n",
    "    \"\"\"\n",
    "    distribution = {}\n",
    "    for scene, dirs in dataset.items():\n",
    "        distribution[scene] = {}\n",
    "        for _, water_percentage in dirs:\n",
    "            bin_index = water_percentage // bin_size\n",
    "            if bin_index not in distribution[scene]:\n",
    "                distribution[scene][bin_index] = 0\n",
    "            distribution[scene][bin_index] += 1\n",
    "    return distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING THE BALANCED DATASET\n",
    "\n",
    "process_dataset(input_dir, output_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
