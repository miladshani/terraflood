{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.402624\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "import affine\n",
    "import os\n",
    "from shapely.geometry import box\n",
    "from rasterio.coords import BoundingBox\n",
    "from rasterio.mask import mask as masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.878592\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input paths\n",
    "load_vv = Path(\"../data/vv/vv.tif\")\n",
    "load_mask = Path(\"../data/mask/merged/mask.tif\")\n",
    "load_dem = Path(\"../data/dem/dem.tif\")\n",
    "\n",
    "# output paths\n",
    "save_vv = Path(\"../data/dataset/vv\")\n",
    "save_mask = Path(\"../data/dataset/mask\")\n",
    "save_dem = Path(\"../data/dataset/dem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "OUTPUT_SIZE = (256, 256)\n",
    "DROPNA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change CRS system\n",
    "# REPROJECTION CRS WITHOUT SAVING\n",
    "# KEEPS IN --> RAM <--\n",
    "\n",
    "\n",
    "def reproject_crs(file_path, target_crs):\n",
    "    \"\"\"Function to load tiff file from path\n",
    "    with desired crs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input GeoTIFF file\n",
    "    src = rio.open(file_path)\n",
    "\n",
    "    # Read metadata\n",
    "    src_crs = src.crs\n",
    "    src_transform = src.transform\n",
    "    src_width = src.width\n",
    "    src_height = src.height\n",
    "\n",
    "    # Calculate the transform for reprojecting\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src_crs, target_crs, src_width, src_height, *src.bounds\n",
    "    )\n",
    "\n",
    "    # Create options for the output file\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update(\n",
    "        {\"crs\": target_crs, \"transform\": transform, \"width\": width, \"height\": height}\n",
    "    )\n",
    "\n",
    "    # Create an in-memory dataset\n",
    "    memfile = MemoryFile()\n",
    "    dst = memfile.open(**kwargs)\n",
    "\n",
    "    # Reproject and write to the in-memory dataset\n",
    "    reproject(\n",
    "        source=rio.band(src, 1),\n",
    "        destination=rio.band(dst, 1),\n",
    "        src_transform=src_transform,\n",
    "        src_crs=src_crs,\n",
    "        dst_transform=transform,\n",
    "        dst_crs=target_crs,\n",
    "        resampling=Resampling.nearest,\n",
    "    )\n",
    "    src.close()\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.042432\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all files with CRS:32632 as example\n",
    "target_crs = CRS.from_epsg(32632)\n",
    "vv = reproject_crs(load_vv, target_crs)\n",
    "mask = reproject_crs(load_mask, target_crs)\n",
    "dem = reproject_crs(load_dem, target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193.754624\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': None, 'width': 14105, 'height': 10932, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(20.0, 0.0, 153265.79316470574,\n",
      "       0.0, -20.0, 1000962.9311765691)}\n",
      "{'driver': 'GTiff', 'dtype': 'uint8', 'nodata': 255.0, 'width': 14135, 'height': 10951, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(19.96365218701852, 0.0, 153227.4398530922,\n",
      "       0.0, -19.96365218701852, 1000925.7648684348)}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -9999.0, 'width': 12093, 'height': 12140, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(91.79988551242911, 0.0, 56178.489241547475,\n",
      "       0.0, -91.79988551242911, 1667057.241646418)}\n"
     ]
    }
   ],
   "source": [
    "print(vv.meta, mask.meta, dem.meta, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193.852928\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789.083648\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundingBox(left=153265.79316470574, bottom=782322.9311765691, right=435365.79316470574, top=1000962.9311765691)\n",
      "BoundingBox(left=153227.4398530922, bottom=782303.8097683949, right=435413.663516599, top=1000925.7648684348)\n",
      "BoundingBox(left=56178.489241547475, bottom=552606.6315255286, right=1166314.5047433528, top=1667057.241646418)\n"
     ]
    }
   ],
   "source": [
    "print(vv.bounds, mask.bounds, dem.bounds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting overlap bounding box between files\n",
    "# So to keep parts of data that are needed in the RAM\n",
    "\n",
    "left = [vv.bounds.left, mask.bounds.left, dem.bounds.left]\n",
    "bottom = [vv.bounds.bottom, mask.bounds.bottom, dem.bounds.bottom]\n",
    "right = [vv.bounds.right, mask.bounds.right, dem.bounds.right]\n",
    "top = [vv.bounds.top, mask.bounds.top, dem.bounds.top]\n",
    "\n",
    "overlap_bounds = BoundingBox(\n",
    "    left=max(left), bottom=max(bottom), right=min(right), top=min(top)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((435365.79316470574 782322.9311765691, 435365.79316470574 1000925.7648684348, 153265.79316470574 1000925.7648684348, 153265.79316470574 782322.9311765691, 435365.79316470574 782322.9311765691))\n"
     ]
    }
   ],
   "source": [
    "# Convert bounds to polygon\n",
    "overlap_polygon = box(*overlap_bounds)\n",
    "print(overlap_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img, crop_transform = masker(dem, shapes=[overlap_polygon], crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2382, 3074)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MemoryFile() out of crop_img\n",
    "profile = dem.profile.copy()\n",
    "profile.update(\n",
    "    driver=\"GTiff\",\n",
    "    height=crop_img.shape[1],\n",
    "    width=crop_img.shape[2],\n",
    "    transform=crop_transform,\n",
    ")\n",
    "\n",
    "memfile = MemoryFile()\n",
    "cropped_dem = memfile.open(**profile)\n",
    "cropped_dem.write(crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff',\n",
       " 'dtype': 'float32',\n",
       " 'nodata': -9999.0,\n",
       " 'width': 3074,\n",
       " 'height': 2382,\n",
       " 'count': 1,\n",
       " 'crs': CRS.from_epsg(32632),\n",
       " 'transform': Affine(91.79988551242911, 0.0, 153210.96822818505,\n",
       "        0.0, -91.79988551242911, 1000957.2723682325)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped_dem.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(91.79988551242911, 0.0, 153210.96822818505,\n",
       "       0.0, -91.79988551242911, 1000957.2723682325)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(crop_img)\n",
    "type(crop_transform)\n",
    "crop_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2382, 3074)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Affine(91.79988551242911, 0.0, 56178.489241547475,\n",
       "       0.0, -91.79988551242911, 1667057.241646418)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12140, 12093)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.049664939879282"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger = dem.shape[0] * dem.shape[1]\n",
    "smaller = crop_img.shape[1] * crop_img.shape[2]\n",
    "\n",
    "bigger / smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change the resolution of files to desired one\n",
    "\n",
    "\n",
    "def rescale_image(input_file, scale_factor):\n",
    "    # Read the data from the source file\n",
    "    src = input_file\n",
    "    data = src.read(\n",
    "        out_shape=(\n",
    "            src.count,\n",
    "            int(src.height * scale_factor),\n",
    "            int(src.width * scale_factor),\n",
    "        ),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    # Update the metadata\n",
    "    transform = src.transform * src.transform.scale(\n",
    "        (src.width / data.shape[-1]), (src.height / data.shape[-2])\n",
    "    )\n",
    "\n",
    "    # Update the profile\n",
    "    profile = src.profile\n",
    "    profile.update(\n",
    "        driver=\"GTiff\",\n",
    "        height=data.shape[1],\n",
    "        width=data.shape[2],\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    memfile = MemoryFile()\n",
    "    scaled_dataset = memfile.open(**profile)\n",
    "    scaled_dataset.write(data)\n",
    "\n",
    "    return scaled_dataset, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981826093509261 4.589994275621455\n"
     ]
    }
   ],
   "source": [
    "# Set resolution to standard\n",
    "RES = 20\n",
    "mask_refactor = mask.res[0] / RES\n",
    "dem_refactor = cropped_dem.res[0] / RES\n",
    "print(mask_refactor, dem_refactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_scaled, _ = rescale_image(mask, mask_refactor)\n",
    "dem_scaled, _ = rescale_image(cropped_dem, dem_refactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': None, 'width': 14105, 'height': 10932, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(20.0, 0.0, 153265.79316470574,\n",
      "       0.0, -20.0, 1000962.9311765691)}\n",
      "{'driver': 'GTiff', 'dtype': 'uint8', 'nodata': 255.0, 'width': 14109, 'height': 10931, 'count': 1, 'crs': CRS.from_epsg(32632), 'transform': Affine(20.000441113013455, 0.0, 153227.4398530922,\n",
      "       0.0, -20.00017885829657, 1000925.7648684348)}\n"
     ]
    }
   ],
   "source": [
    "print(vv.meta, mask_scaled.meta, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155275.79316470574 998552.9311765691\n"
     ]
    }
   ],
   "source": [
    "x, y = vv.xy(120, 100)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm = mask_scaled.read(1)\n",
    "mmmm = mask.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199.046656\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199.161344\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = vv.transform * (120, 100)\n",
    "# print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 100\n"
     ]
    }
   ],
   "source": [
    "row, col = vv.index(x, y)\n",
    "print(row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "\n",
    "    # OK\n",
    "    def __init__(self):\n",
    "        \"\"\"Initiates an empty list. To be fed with different images data\"\"\"\n",
    "        self.images = []\n",
    "        self.ref_flag = False\n",
    "\n",
    "        self.clipped_addresses = []\n",
    "\n",
    "    # OK\n",
    "    # THE WAT THAT NO DATA ADDED?\n",
    "    def add(self, image, name: str, set_nodata: int = 0):\n",
    "        \"\"\"Creates a dictionary of infromation about the given image.\n",
    "        Then adds that dict to the images_data list.\n",
    "        \"\"\"\n",
    "\n",
    "        # Correcting Nodata\n",
    "        if image.nodata == None:\n",
    "            image.nodata = set_nodata\n",
    "\n",
    "        image_dict = dict()\n",
    "        image_dict[\"name\"] = name\n",
    "        image_dict[\"image\"] = image\n",
    "        image_dict[\"band\"] = image.read(1)\n",
    "\n",
    "        self.images.append(image_dict)\n",
    "\n",
    "    # OK\n",
    "    def set_ref_image(self, name: str = \"vv\"):\n",
    "        \"\"\"Sets the image file which all dataset should be cliped\n",
    "        with respect to that.\n",
    "        Input:str -> name of the image\n",
    "        Output:Bool -> True if done, False name not in the list\n",
    "        \"\"\"\n",
    "        # Checks if the name is in added images list\n",
    "        check_availibility = [True for image in self.images if image[\"name\"] == name]\n",
    "        if not check_availibility:\n",
    "            return False\n",
    "\n",
    "        for image in self.images:\n",
    "            if image[\"name\"] == name:\n",
    "                self.ref_name = name\n",
    "                self.ref_image = image[\"image\"]\n",
    "                self.ref_crs = image[\"image\"].crs\n",
    "                self.ref_res = image[\"image\"].res\n",
    "                self.ref_shape = image[\"image\"].shape\n",
    "\n",
    "        self.refrence_flag = True\n",
    "        return True\n",
    "\n",
    "    # OUTPUT IS NOT IMAGE, IS A LIST\n",
    "    # NEED CHANGE?\n",
    "    # Self.band needs to change\n",
    "    def _create_clipped_image(self, image, band, row, col, height, width, name):\n",
    "\n",
    "        ### need change self.band\n",
    "        # band data array\n",
    "\n",
    "        clipped_band = band[\n",
    "            row : row + height,\n",
    "            col : col + width,\n",
    "        ]\n",
    "        clipped_band = np.array(clipped_band)\n",
    "\n",
    "        # Positioning\n",
    "        tcol, trow = image.transform * (col, row)\n",
    "        new_transform = affine.Affine(\n",
    "            image.transform[0],\n",
    "            image.transform[1],\n",
    "            tcol,\n",
    "            image.transform[3],\n",
    "            image.transform[4],\n",
    "            trow,\n",
    "        )\n",
    "\n",
    "        # creating clipped_image\n",
    "        return_image = [\n",
    "            clipped_band,\n",
    "            image.crs,\n",
    "            new_transform,\n",
    "            clipped_band.shape[0],\n",
    "            clipped_band.shape[1],\n",
    "            image.dtypes[0],\n",
    "            image.nodata,\n",
    "            name,\n",
    "        ]\n",
    "        return return_image\n",
    "\n",
    "    def _check_complete(self, images, height, width):\n",
    "        \"\"\"\n",
    "        If any image in the same coordination has\n",
    "        nodata value returns False, otherwise True.\n",
    "        \"\"\"\n",
    "        # for image in images:\n",
    "        #     with image.read(1) as band:\n",
    "        #         if sum(sum(band == image.nodata)):\n",
    "        #             return False\n",
    "        # return True\n",
    "\n",
    "        for image in images:\n",
    "            if sum(sum(image[0] == image[6])):\n",
    "                return False\n",
    "            if image[0].shape != (height, width):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _save_image(self, save_path_format, image, col, row):\n",
    "        \"\"\"\n",
    "        Saves Clipped image into file\n",
    "        \"\"\"\n",
    "        name = image[7]\n",
    "\n",
    "        file_name = save_path_format.format(name=name, col=col, row=row)\n",
    "        file_name = Path(file_name)\n",
    "\n",
    "        os.makedirs(os.path.split(file_name)[0], exist_ok=True)\n",
    "\n",
    "        with rio.open(\n",
    "            file_name,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=image[3],\n",
    "            width=image[4],\n",
    "            count=1,\n",
    "            dtype=image[5],\n",
    "            crs=image[1],\n",
    "            transform=image[2],\n",
    "        ) as dst:\n",
    "            dst.write(image[0], 1)\n",
    "        self.clipped_addresses.append(file_name)\n",
    "\n",
    "    def _xy_from_row_col(self, image, row, col):\n",
    "        \"\"\"Returns coordinate of a pixel in one image from it's (row,col)\"\"\"\n",
    "        x, y = image.xy(row, col)\n",
    "        return x, y\n",
    "\n",
    "    def _row_col_from_xy(self, image, x, y):\n",
    "        \"\"\"Returns (row,col) position of a pixel from it's coordinate\"\"\"\n",
    "        row, col = image.index(x, y)\n",
    "        return row, col\n",
    "\n",
    "    def run(self, height: int = 256, width: int = 256, only_complete: bool = True):\n",
    "\n",
    "        save_path_format = \"../data/dataset/{name}/{name}_x{row}_y{col}.tif\"\n",
    "\n",
    "        row = 0\n",
    "        while row < self.ref_shape[0]:\n",
    "            col = 0\n",
    "            while col < self.ref_shape[1]:\n",
    "\n",
    "                clipped_images = []\n",
    "                for img in self.images:\n",
    "\n",
    "                    name = img[\"name\"]\n",
    "                    image = img[\"image\"]\n",
    "                    band = img[\"band\"]\n",
    "\n",
    "                    # Coverting row,col of refrence image to row,col of the current image\n",
    "                    x, y = self._xy_from_row_col(self.ref_image, row=row, col=col)\n",
    "                    trow, tcol = self._row_col_from_xy(image=image, x=x, y=y)\n",
    "\n",
    "                    clipped_image = self._create_clipped_image(\n",
    "                        image, band, trow, tcol, height, width, name\n",
    "                    )\n",
    "                    clipped_images.append(clipped_image)\n",
    "\n",
    "                ### _check_complete\n",
    "                complete_check = self._check_complete(clipped_images, height, width)\n",
    "\n",
    "                ### save images\n",
    "                if complete_check:\n",
    "                    for image in clipped_images:\n",
    "                        self._save_image(save_path_format, image, col, row)\n",
    "                ### add to STAC\n",
    "                ### append saved images into a list?\n",
    "\n",
    "                # Update column position\n",
    "                col = col + width\n",
    "\n",
    "            # Update row position\n",
    "            row = row + height\n",
    "\n",
    "        print(\"Tiles saved successfully\")\n",
    "        return self.clipped_addresses\n",
    "\n",
    "    # -------------- later ------------\n",
    "    def _get_mask_coverage(self):\n",
    "        pass\n",
    "\n",
    "    def _add_to_stac(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('uint8',)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rasterio.io.DatasetWriter"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles saved successfully\n"
     ]
    }
   ],
   "source": [
    "ds_generator = DatasetGenerator()\n",
    "ds_generator.add(vv, name=\"vv\", set_nodata=0)\n",
    "ds_generator.add(mask_scaled, name=\"mask\")\n",
    "ds_generator.add(dem_scaled, name=\"dem\")\n",
    "\n",
    "ds_generator.set_ref_image(\"vv\")\n",
    "paths = ds_generator.run(height=256, width=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385.974272\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "print(process.memory_info().rss / 10**6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "terraflood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
